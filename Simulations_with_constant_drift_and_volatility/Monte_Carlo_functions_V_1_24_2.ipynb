{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of packages\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import sqrtm #matrix square root\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f823a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skripts_work():\n",
    "  return \"Monte carlo skript functions integrated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc12678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elementary functions for monte carlo simulations\n",
    "\n",
    "\n",
    "#fast monte carlo simulation with fixed QV\n",
    "\n",
    "def fast_monte_carlo_simulation_with_fixed_QV(Sigma_true, Sigma_true_denoised, sampling_interval, drift, L_lambda=6,\n",
    "                                              number_of_simulations=100, number_error_types=12, progress_number=50):\n",
    "    \"\"\"\n",
    "    Simulate number_of_simulation times paths with Sigma_true, drift and sampling_interval. Always calculate rv an prv.\n",
    "    Use the fast functions to do so. Then returns properties of the two estimators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma_true : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    Sigma_true_denoised : numpy.ndarray\n",
    "        True QV of the setting without vanishing components in the SVD.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    L_lambda : int\n",
    "        The hyperparameter L_lambda defines the number of subsamples used in the choice of the tuning parameter lambda.\n",
    "    number_of_simulations : int\n",
    "        Number of simulated log-prices that are analysed with the estimators.\n",
    "    number_error_types : int\n",
    "        Number of different errors returned by this function.\n",
    "    progress_number : int\n",
    "        The integer decides after how many simulations the progress is printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    eigenvalues_rv : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the rv for the corresponding simulation. They are sorted decreasingly.\n",
    "    eigenvalues_prv : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the prv for the corresponding simulation. They are sorted decreasingly.\n",
    "\n",
    "\n",
    "    lambdas_used : numpy.ndarray\n",
    "        Array containing the used tuning parameters lambda of the prv estimators for each simulation.\n",
    "\n",
    "\n",
    "    rank_rv : numpy.ndarray\n",
    "        Array containing the ranks of the rv estimators for each simulation.\n",
    "    rank_prv : numpy.ndarray\n",
    "        Array containing the ranks of the prv estimators for each simulation.\n",
    "\n",
    "    all_errors : numpy.ndarray\n",
    "        A matrix with several columns, each row describes a simulation and each column an error.\n",
    "        In this order, the different columns contain:\n",
    "\n",
    "        -squared_2_norm_error_rv : The squared Frobenius norm errors of the rv estimators for each simulation.\n",
    "        -squared_2_norm_error_prv : The squared Frobenius norm errors of the prv estimators for each simulation.\n",
    "        -1_norm_error_rv : The nuclear norm errors of the rv estimators for each simulation.\n",
    "        -1_norm_error_prv : The nuclear norm errors of the prv estimators for each simulation.\n",
    "        -spectral_norm_error_rv : The spectral norm errors of the rv estimators for each simulation.\n",
    "        -spectral_norm_error_prv : The spectral norm errors of the prv estimators for each simulation.\n",
    "\n",
    "        -denoised_squared_2_norm_error_rv : The squared Frobenius norm errors of the rv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "        -denoised_squared_2_norm_error_prv : The squared Frobenius norm errors of the prv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "        -denoised_1_norm_error_rv : The nuclear norm errors of the rv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "        -denoised_1_norm_error_prv : The nuclear norm errors of the prv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "        -denoised_spectral_norm_error_rv : The spectral norm errors of the rv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "        -denoised_spectral_norm_error_prv : The spectral norm errors of the prv estimators for each simulation\n",
    "        with Sigma_true_denoised as inference target.\n",
    "    \"\"\"\n",
    "    d=Sigma_true.shape[0]\n",
    "    vola=sqrtm(Sigma_true)\n",
    "\n",
    "    #arrays of returns\n",
    "    eigenvalues_rv = np.zeros((number_of_simulations, d))\n",
    "    eigenvalues_prv = np.zeros((number_of_simulations, d))\n",
    "    lambdas_used = np.zeros(number_of_simulations)\n",
    "    rank_rv = np.zeros(number_of_simulations)\n",
    "    rank_prv = np.zeros(number_of_simulations)\n",
    "    all_errors = np.zeros((number_of_simulations, number_error_types))\n",
    "\n",
    "\n",
    "    for i in range(0,number_of_simulations):\n",
    "        returns=fast_increments_generator(volatility=vola, drift=drift, sampling_interval=sampling_interval)\n",
    "\n",
    "        rv=fast_realized_variance(returns)\n",
    "        lambda_used=lambda_selection_via_subsampling_procedure(returns, L_lambda=L_lambda)\n",
    "        prv, rank_of_prv=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_used)\n",
    "\n",
    "        eigenvalues_rv[i,:] = np.sort(np.linalg.eigh(rv)[0])[::-1] #sort creates increasing, now decreasing\n",
    "        eigenvalues_prv[i,:] = np.sort(np.linalg.eigh(prv)[0])[::-1] #sort creates increasing, now decreasing\n",
    "        lambdas_used[i] = lambda_used\n",
    "        rank_rv[i] = np.linalg.matrix_rank(rv)\n",
    "        rank_prv[i] = rank_of_prv\n",
    "\n",
    "        all_errors[i,0] = np.linalg.norm(rv-Sigma_true, 'fro')**2 #fro=Frobenius\n",
    "        all_errors[i,1] = np.linalg.norm(prv-Sigma_true, 'fro')**2\n",
    "        all_errors[i,2] = np.linalg.norm(rv-Sigma_true, 'nuc')# nuc=Nuclear\n",
    "        all_errors[i,3] = np.linalg.norm(prv-Sigma_true, 'nuc')\n",
    "        all_errors[i,4] = np.linalg.norm(rv-Sigma_true, 2)# 2=Spectral\n",
    "        all_errors[i,5] = np.linalg.norm(prv-Sigma_true, 2)\n",
    "\n",
    "        all_errors[i,6] = np.linalg.norm(rv-Sigma_true_denoised, 'fro')**2 #fro=Frobenius\n",
    "        all_errors[i,7] = np.linalg.norm(prv-Sigma_true_denoised, 'fro')**2\n",
    "        all_errors[i,8] = np.linalg.norm(rv-Sigma_true_denoised, 'nuc')# nuc=Nuclear\n",
    "        all_errors[i,9] = np.linalg.norm(prv-Sigma_true_denoised, 'nuc')\n",
    "        all_errors[i,10] = np.linalg.norm(rv-Sigma_true_denoised, 2)# 2=Spectral\n",
    "        all_errors[i,11] = np.linalg.norm(prv-Sigma_true_denoised, 2)\n",
    "\n",
    "        if i%progress_number==0:\n",
    "            print(f'{i} simulations: finished.')\n",
    "\n",
    "    return eigenvalues_rv , eigenvalues_prv , lambdas_used , rank_rv , rank_prv , all_errors\n",
    "\n",
    "\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8488f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for sensitivity analysis of tuning parameters\n",
    "\n",
    "\n",
    "#L_lambda\n",
    "\n",
    "#function that finds all divisors of n\n",
    "\n",
    "def divisors(n):\n",
    "    \"\"\"\n",
    "    Returns all positive divisors of n.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Integer for which divisors are calculated.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    divisors : numpy.ndarray\n",
    "        Array containing all divisors.\n",
    "    \"\"\"\n",
    "    small = []\n",
    "    large = []\n",
    "\n",
    "    for i in range(1, int(np.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            small.append(i)\n",
    "            if i != n // i:    #n//i is division and than floored , != is not equal\n",
    "                large.append(n // i)\n",
    "\n",
    "    return np.array(small + large[::-1])\n",
    "\n",
    "\n",
    "#fast sensitivity analysis of L_lambda\n",
    "\n",
    "def fast_sensitivity_analysis_for_L_lambda_with_fixed_QV(Sigma_true, Sigma_true_denoised, sampling_interval, drift,\n",
    "                                              number_of_simulations=100, number_error_types=2, progress_number=50):\n",
    "    \"\"\"\n",
    "    Evaluate the influence of the hyperparameter L_lambda by using different values\n",
    "    of it in the calculation of the PRV estimator.\n",
    "    Then, return the final tuning parameters lambda and the rank and estimation errors of the PRV estimator\n",
    "    in the squared Frobenius norm .\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma_true : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    Sigma_true_denoised : numpy.ndarray\n",
    "        True QV of the setting without vanishing components in the SVD.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    number_of_simulations : int\n",
    "        Number of simulated log-prices that are analysed with the estimators.\n",
    "    number_error_types : int\n",
    "        Number of different errors returned by this function.\n",
    "    progress_number : int\n",
    "        The integer decides after how many simulations the progress is printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    L_lambdas : numpy.ndarray\n",
    "        Vector containing all analyzed L_lambdas.\n",
    "\n",
    "    lambdas_used : numpy.ndarray\n",
    "        Matrix containing the used tuning parameters lambda of the prv estimators.\n",
    "        Each simulation is a row, each L_lambda choice corresponds to a column.\n",
    "\n",
    "    rank_prv : numpy.ndarray\n",
    "        Matrix containing the ranks of the prv estimators.\n",
    "        Each simulation is a row, each L_lambda choice corresponds to a column.\n",
    "\n",
    "    squared_2_norm_error_prv : numpy.ndarray\n",
    "        Matrix containing the squared Frobenius norm errors of the prv estimators.\n",
    "        Each simulation is a row, each L_lambda choice corresponds to a column.\n",
    "    denoised_squared_2_norm_error_prv : numpy.ndarray\n",
    "        Matrix containing the squared Frobenius norm errors of the prv estimators with Sigma_true_denoised as inference target.\n",
    "        Each simulation is a row, each L_lambda choice corresponds to a column.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d=Sigma_true.shape[0]\n",
    "    vola=sqrtm(Sigma_true)\n",
    "\n",
    "    n=int(np.floor(1/sampling_interval))\n",
    "    L_lambdas=divisors(n)\n",
    "\n",
    "    #arrays of returns\n",
    "    lambdas_used = np.zeros((number_of_simulations, len(L_lambdas)))\n",
    "    rank_prv = np.zeros((number_of_simulations, len(L_lambdas)))\n",
    "    squared_2_norm_error_prv = np.zeros((number_of_simulations, len(L_lambdas)))\n",
    "    denoised_squared_2_norm_error_prv = np.zeros((number_of_simulations, len(L_lambdas)))\n",
    "\n",
    "\n",
    "    for i in range(0,number_of_simulations):\n",
    "        returns=fast_increments_generator(volatility=vola, drift=drift, sampling_interval=sampling_interval)\n",
    "\n",
    "        rv=fast_realized_variance(returns)\n",
    "\n",
    "        for z in range(len(L_lambdas)):\n",
    "            lambda_used=lambda_selection_via_subsampling_procedure(returns, L_lambda=L_lambdas[z])\n",
    "            prv, rank_of_prv=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_used)\n",
    "\n",
    "            lambdas_used[i,z] = lambda_used\n",
    "            rank_prv[i,z] = rank_of_prv\n",
    "\n",
    "            squared_2_norm_error_prv[i,z] = np.linalg.norm(prv-Sigma_true, 'fro')**2\n",
    "            denoised_squared_2_norm_error_prv[i,z] = np.linalg.norm(prv-Sigma_true_denoised, 'fro')**2\n",
    "\n",
    "\n",
    "        if i%progress_number==0:\n",
    "            print(f'{i} simulations: finished.')\n",
    "\n",
    "    return L_lambdas , lambdas_used , rank_prv , squared_2_norm_error_prv , denoised_squared_2_norm_error_prv\n",
    "\n",
    "\n",
    "#tuning parameter lambda\n",
    "\n",
    "#fast sensitivity analysis of lambda\n",
    "\n",
    "def fast_sensitivity_analysis_for_lambda_with_fixed_QV(Sigma_true, Sigma_true_denoised, sampling_interval, drift,\n",
    "                                                       lambda_prefactors, L_lambda=6,\n",
    "                                                       number_of_simulations=100, number_error_types=2, progress_number=50):\n",
    "    \"\"\"\n",
    "    Evaluate the influence of thetuning parameter lambda by using different values\n",
    "    of it in the calculation of the PRV estimator.\n",
    "    Then, return the rank and the estimation errors of the PRV estimator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma_true : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    Sigma_true_denoised : numpy.ndarray\n",
    "        True QV of the setting without vanishing components in the SVD.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    lambda_prefactors : numpy.ndarray\n",
    "        Vector containing all the prefactors that are multiplied with the actual lambda_subsam value to get a tuning parameter.\n",
    "    L_lambda : int\n",
    "        The hyperparameter L_lambda defines the number of subsamples used in the choice of the tuning parameter lambda.\n",
    "    number_of_simulations : int\n",
    "        Number of simulated log-prices that are analysed with the estimators.\n",
    "    number_error_types : int\n",
    "        Number of different errors returned by this function.\n",
    "    progress_number : int\n",
    "        The integer decides after how many simulations the progress is printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    lambdas_used : numpy.ndarray\n",
    "        Matrix containing the used tuning parameters lambda of the prv estimators.\n",
    "        Each simulation is a row, each lambda prefactor corresponds to a column.\n",
    "\n",
    "    rank_prv : numpy.ndarray\n",
    "        Matrix containing the ranks of the prv estimators.\n",
    "        Each simulation is a row, each lambda prefactor corresponds to a column.\n",
    "\n",
    "    squared_2_norm_error_prv : numpy.ndarray\n",
    "        Matrix containing the squared Frobenius norm errors of the prv estimators.\n",
    "        Each simulation is a row, each lambda prefactor corresponds to a column.\n",
    "    denoised_squared_2_norm_error_prv : numpy.ndarray\n",
    "        Matrix containing the squared Frobenius norm errors of the prv estimators with Sigma_true_denoised as inference target.\n",
    "        Each simulation is a row, each lambda prefactor corresponds to a column.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d=Sigma_true.shape[0]\n",
    "    vola=sqrtm(Sigma_true)\n",
    "\n",
    "    #arrays of returns\n",
    "    lambdas_used = np.zeros((number_of_simulations, len(lambda_prefactors)))\n",
    "    rank_prv = np.zeros((number_of_simulations, len(lambda_prefactors)))\n",
    "    squared_2_norm_error_prv = np.zeros((number_of_simulations, len(lambda_prefactors)))\n",
    "    denoised_squared_2_norm_error_prv = np.zeros((number_of_simulations, len(lambda_prefactors)))\n",
    "\n",
    "\n",
    "    for i in range(0,number_of_simulations):\n",
    "        returns=fast_increments_generator(volatility=vola, drift=drift, sampling_interval=sampling_interval)\n",
    "\n",
    "        rv=fast_realized_variance(returns)\n",
    "        lambda_used=lambda_selection_via_subsampling_procedure(returns, L_lambda=L_lambda)\n",
    "\n",
    "        for z in range(len(lambda_prefactors)):\n",
    "            prv, rank_of_prv=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_prefactors[z]*lambda_used)\n",
    "\n",
    "            lambdas_used[i,z] = lambda_prefactors[z]*lambda_used\n",
    "            rank_prv[i,z] = rank_of_prv\n",
    "\n",
    "            squared_2_norm_error_prv[i,z] = np.linalg.norm(prv-Sigma_true, 'fro')**2\n",
    "            denoised_squared_2_norm_error_prv[i,z] = np.linalg.norm(prv-Sigma_true_denoised, 'fro')**2\n",
    "\n",
    "\n",
    "        if i%progress_number==0:\n",
    "            print(f'{i} simulations: finished.')\n",
    "\n",
    "    return lambdas_used , rank_prv , squared_2_norm_error_prv , denoised_squared_2_norm_error_prv\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb81d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for comparison of theoretical findings with simulations\n",
    "\n",
    "#formulas for the tuning parameters\n",
    "\n",
    "def lambda_esterr_calculation(Sigma, drift, sampling_interval, tau, gamma= 82*10**(6)):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the positive tuning parameter lambda_esterr from formula (7.9).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    tau : float\n",
    "        Positive argument of lambda_esterr in (7.9).\n",
    "    gamma : float\n",
    "        Absolute constant gamma from Theorem 4.7.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lambda_esterr : float\n",
    "        Positive tuning parameter lambda_esterr from formula (7.9).\n",
    "    index_of_maximal_value : int\n",
    "        Position of the argument in the maximum of lambda_esterr in (7.9) that attains the maximum (0,1,2 or 3).\n",
    "\n",
    "    \"\"\"\n",
    "    v_mu=np.linalg.norm(drift)**2\n",
    "    v_c_2=np.trace(Sigma)\n",
    "    #v_c_2=np.linalg.norm(sqrtm(Sigma), 'fro')**2   # 'fro' is Frobenius norm\n",
    "    v_c_inf=np.linalg.norm(Sigma, 2)   # 2 is spectral norm\n",
    "    d=Sigma.shape[0]\n",
    "\n",
    "    lambda_esterr=max(20*(v_c_2*v_mu*sampling_interval)/v_c_inf, 20*(v_c_2*v_mu*sampling_interval)**0.5,\n",
    "                     ((4*gamma*(tau+np.log(6*d)))*(v_c_2*v_c_inf*sampling_interval))**0.5,\n",
    "                     (2*gamma/2255)*(tau+np.log(6*d))*v_c_2*sampling_interval)\n",
    "\n",
    "    index_of_maximal_value=np.argmax(np.array([220*(v_c_2*v_mu*sampling_interval)/v_c_inf, 20*(v_c_2*v_mu*sampling_interval)**0.5,\n",
    "                     ((4*gamma*(tau+np.log(6*d)))*(v_c_2*v_c_inf*sampling_interval))**0.5,\n",
    "                     (2*gamma/2255)*(tau+np.log(6*d))*v_c_2*sampling_interval]))\n",
    "\n",
    "    return lambda_esterr , index_of_maximal_value\n",
    "\n",
    "def lambda_conint_calculation(Sigma, drift, sampling_interval, alpha=0.05, gamma= 82*10**(6)):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the positive tuning parameter lambda_conint from formula (7.11).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    alpha : float\n",
    "        Positive argument alpha in (0,1) of lambda_conint in (7.11). It is 1 minus the confidence level.\n",
    "    gamma : float\n",
    "        Absolute constant gamma from Theorem 4.7.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lambda_esterr : float\n",
    "        Positive tuning parameter lambda_conint from formula (7.11).\n",
    "    index_of_maximal_value : int\n",
    "        Position of the argument in the maximum of lambda_conint in (7.11) that attains the maximum (0,1,2 or 3).\n",
    "\n",
    "    \"\"\"\n",
    "    v_mu=np.linalg.norm(drift)**2\n",
    "    v_c_2=np.trace(Sigma)\n",
    "    #v_c_2=np.linalg.norm(sqrtm(Sigma), 'fro')**2   # 'fro' is Frobenius norm\n",
    "    v_c_inf=np.linalg.norm(Sigma, 2)   # 2 is spectral norm\n",
    "    d=Sigma.shape[0]\n",
    "\n",
    "    lambda_conint=max(20*(v_c_2*v_mu*sampling_interval)**0.5,\n",
    "                     ((4*gamma*np.log(6*d/alpha))*(v_c_2*v_c_inf*sampling_interval))**0.5,\n",
    "                      20*(v_c_2*v_mu*sampling_interval)/v_c_inf,\n",
    "                     (2*gamma/2255)*np.log(6*d/alpha)*v_c_2*sampling_interval)\n",
    "\n",
    "    index_of_maximal_value=np.argmax(np.array([20*(v_c_2*v_mu*sampling_interval)**0.5,\n",
    "                     ((4*gamma*np.log(6*d/alpha))*(v_c_2*v_c_inf*sampling_interval))**0.5,\n",
    "                      20*(v_c_2*v_mu*sampling_interval)/v_c_inf,\n",
    "                     (2*gamma/2255)*np.log(6*d/alpha)*v_c_2*sampling_interval]))\n",
    "\n",
    "    return lambda_conint , index_of_maximal_value\n",
    "\n",
    "\n",
    "\n",
    "#fast monte carlo simulation for the comparison with theory\n",
    "\n",
    "def monte_carlo_simulation_for_theory(Sigma_true, Sigma_true_denoised, sampling_interval, drift, tau, L_lambda=6,\n",
    "                                      alpha=0.05, gamma= 82*10**(6),\n",
    "                                      number_of_simulations=100, number_error_types=12, progress_number=50):\n",
    "    \"\"\"\n",
    "    Simulate number_of_simulation times paths with Sigma_true, drift and sampling_interval.\n",
    "    Then, determine for each path lambda-subsam. Always calculate the prv for lambda_subsam, lambda_esterr and lambda_conint.\n",
    "    Then returns properties of the 3 estimators (3 different prv estimators, one per choice of lambda).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Sigma_true : numpy.ndarray\n",
    "        True QV of the setting.\n",
    "    Sigma_true_denoised : numpy.ndarray\n",
    "        True QV of the setting without vanishing components in the SVD.\n",
    "    sampling_interval : float\n",
    "        Time diffference between observations on [o,1].\n",
    "    drift : numpy.ndarray\n",
    "        True drift of the setting.\n",
    "    tau : float\n",
    "        Positive argument of lambda_esterr in (7.9).\n",
    "    L_lambda : int\n",
    "        The hyperparameter L_lambda defines the number of subsamples used in the choice of the tuning parameter lambda.\n",
    "    alpha : float\n",
    "        Positive argument alpha in (0,1) of lambda_conint in (7.11). It is 1 minus the confidence level.\n",
    "    gamma : float\n",
    "        Absolute constant gamma from Theorem 4.7.\n",
    "    number_of_simulations : int\n",
    "        Number of simulated log-prices that are analysed with the estimators.\n",
    "    number_error_types : int\n",
    "        Number of different errors returned by this function.\n",
    "    progress_number : int\n",
    "        The integer decides after how many simulations the progress is printed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    lambdas_subsam_used : numpy.ndarray\n",
    "        Array containing the used tuning parameters lambda_subsam of the prv estimators for each path.\n",
    "    lambda_esterr : float\n",
    "        Tuning parameter lambda_esterr of the prv estimators used in every path.\n",
    "    index_of_maximal_value_esterr : int\n",
    "        Position of the argument in the maximum of lambda_esterr in (7.9) that attains the maximum (0,1,2 or 3).\n",
    "    lambda_conint : float\n",
    "        Tuning parameter lambda_conint of the prv estimators used in every path.\n",
    "    index_of_maximal_value_conint : int\n",
    "        Position of the argument in the maximum of lambda_conint in (7.11) that attains the maximum (0,1,2 or 3).\n",
    "\n",
    "    eigenvalues_rv : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the rv for the corresponding simulation. They are sorted decreasingly.\n",
    "    eigenvalues_prv_subsam : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the prv for the corresponding simulation. They are sorted decreasingly.\n",
    "    eigenvalues_prv_esterr : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the prv for the corresponding simulation. They are sorted decreasingly.\n",
    "    eigenvalues_prv_conint : numpy.ndarray\n",
    "        Each row is an array of the eigenvalues of the prv for the corresponding simulation. They are sorted decreasingly.\n",
    "\n",
    "\n",
    "    rank_rv : numpy.ndarray\n",
    "        Array containing the ranks of the rv estimators for each simulation.\n",
    "    rank_prv : numpy.ndarray\n",
    "        Matrix containing the ranks of the prv estimators for each simulation.\n",
    "        Each column belongs to a special choice of the tuning parameter: lambda_subsam, lambda_esterr and lambda_conint.\n",
    "\n",
    "    all_errors : numpy.ndarray\n",
    "        A matrix with several columns, each row describes a simulation and each column an error.\n",
    "        In this order, the different columns contain:\n",
    "\n",
    "        -squared_2_norm_error_rv : The squared Frobenius norm errors of the rv estimators for each simulation.\n",
    "        -squared_2_norm_error_prv_subsam : The squared Frobenius norm errors of the prv estimators for each simulation.\n",
    "        -squared_2_norm_error_prv_esterr : The squared Frobenius norm errors of the prv estimators for each simulation.\n",
    "        -squared_2_norm_error_prv_conint : The squared Frobenius norm errors of the prv estimators for each simulation.\n",
    "\n",
    "        -1_norm_error_rv : The nuclear norm errors of the rv estimators for each simulation.\n",
    "        -1_norm_error_prv_subsam : The nuclear norm errors of the prv estimators for each simulation.\n",
    "        -1_norm_error_prv_esterr : The nuclear norm errors of the prv estimators for each simulation.\n",
    "        -1_norm_error_prv_conint : The nuclear norm errors of the prv estimators for each simulation.\n",
    "\n",
    "        -spectral_norm_error_rv : The spectral norm errors of the rv estimators for each simulation.\n",
    "        -spectral_norm_error_prv_subsam : The spectral norm errors of the prv estimators for each simulation.\n",
    "        -spectral_norm_error_prv_esterr : The spectral norm errors of the prv estimators for each simulation.\n",
    "        -spectral_norm_error_prv_conint : The spectral norm errors of the prv estimators for each simulation.\n",
    "\n",
    "    \"\"\"\n",
    "    d=Sigma_true.shape[0]\n",
    "    vola=sqrtm(Sigma_true)\n",
    "\n",
    "    lambda_esterr, index_of_maximal_value_esterr=lambda_esterr_calculation(Sigma_true, drift, sampling_interval, tau, gamma)\n",
    "    lambda_conint, index_of_maximal_value_conint=lambda_conint_calculation(Sigma_true, drift, sampling_interval, alpha, gamma)\n",
    "\n",
    "    #arrays of returns\n",
    "    lambdas_subsam_used = np.zeros(number_of_simulations)\n",
    "\n",
    "    eigenvalues_rv = np.zeros((number_of_simulations, d))\n",
    "    eigenvalues_prv_subsam = np.zeros((number_of_simulations, d))\n",
    "    eigenvalues_prv_esterr = np.zeros((number_of_simulations, d))\n",
    "    eigenvalues_prv_conint = np.zeros((number_of_simulations, d))\n",
    "\n",
    "    rank_rv = np.zeros(number_of_simulations)\n",
    "    rank_prv = np.zeros((number_of_simulations, 3))\n",
    "    all_errors = np.zeros((number_of_simulations, number_error_types))\n",
    "\n",
    "\n",
    "    for i in range(0,number_of_simulations):\n",
    "        returns=fast_increments_generator(volatility=vola, drift=drift, sampling_interval=sampling_interval)\n",
    "\n",
    "        rv=fast_realized_variance(returns)\n",
    "        lambda_subsam_used=lambda_selection_via_subsampling_procedure(returns, L_lambda=L_lambda)\n",
    "        prv_subsam, rank_of_prv_subsam=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_subsam_used)\n",
    "\n",
    "        prv_esterr, rank_of_prv_esterr=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_esterr)\n",
    "        prv_conint, rank_of_prv_conint=penalized_realized_variance_for_given_lambda_and_RV(rv, lambda_conint)\n",
    "\n",
    "        eigenvalues_rv[i,:] = np.sort(np.linalg.eigh(rv)[0])[::-1] #sort creates increasing, now decreasing\n",
    "        eigenvalues_prv_subsam[i,:] = np.sort(np.linalg.eigh(prv_subsam)[0])[::-1] #sort creates increasing, now decreasing\n",
    "        eigenvalues_prv_esterr[i,:] = np.sort(np.linalg.eigh(prv_esterr)[0])[::-1] #sort creates increasing, now decreasing\n",
    "        eigenvalues_prv_conint[i,:] = np.sort(np.linalg.eigh(prv_conint)[0])[::-1] #sort creates increasing, now decreasing\n",
    "\n",
    "        lambdas_subsam_used[i] = lambda_subsam_used\n",
    "\n",
    "        rank_rv[i] = np.linalg.matrix_rank(rv)\n",
    "        rank_prv[i,0] = rank_of_prv_subsam\n",
    "        rank_prv[i,1] = rank_of_prv_esterr\n",
    "        rank_prv[i,2] = rank_of_prv_conint\n",
    "\n",
    "        all_errors[i,0] = np.linalg.norm(rv-Sigma_true, 'fro')**2 #fro=Frobenius\n",
    "        all_errors[i,1] = np.linalg.norm(prv_subsam-Sigma_true, 'fro')**2\n",
    "        all_errors[i,2] = np.linalg.norm(prv_esterr-Sigma_true, 'fro')**2\n",
    "        all_errors[i,3] = np.linalg.norm(prv_conint-Sigma_true, 'fro')**2\n",
    "\n",
    "        all_errors[i,4] = np.linalg.norm(rv-Sigma_true, 'nuc')# nuc=Nuclear\n",
    "        all_errors[i,5] = np.linalg.norm(prv_subsam-Sigma_true, 'nuc')\n",
    "        all_errors[i,6] = np.linalg.norm(prv_esterr-Sigma_true, 'nuc')\n",
    "        all_errors[i,7] = np.linalg.norm(prv_conint-Sigma_true, 'nuc')\n",
    "\n",
    "        all_errors[i,8] = np.linalg.norm(rv-Sigma_true, 2)# 2=Spectral\n",
    "        all_errors[i,9] = np.linalg.norm(prv_subsam-Sigma_true, 2)\n",
    "        all_errors[i,10] = np.linalg.norm(prv_esterr-Sigma_true, 2)\n",
    "        all_errors[i,11] = np.linalg.norm(prv_conint-Sigma_true, 2)\n",
    "\n",
    "\n",
    "        if i%progress_number==0:\n",
    "            print(f'{i} simulations: finished.')\n",
    "\n",
    "    return (lambdas_subsam_used, lambda_esterr, index_of_maximal_value_esterr, lambda_conint, index_of_maximal_value_conint,\n",
    "            eigenvalues_rv , eigenvalues_prv_subsam , eigenvalues_prv_esterr , eigenvalues_prv_conint ,\n",
    "            rank_rv , rank_prv , all_errors)\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
